{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705bad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ea2d3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(sitk.Resample)\n",
    "resampler = sitk.ResampleImageFilter()\n",
    "#image = sitk.ReadImage(\"3DT1.nii.gz\", sitk.sitkFloat32)\n",
    "\n",
    "#image."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188a1d0",
   "metadata": {},
   "source": [
    "## Image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3290076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_and_label_resampler(image, label_image, ref_image):\n",
    "    \"\"\"\n",
    "    Resample an image or label_image into the reference physical space\n",
    "    At the end images and labels will have same 1 mm x 1mm 1 x 1mm voxel size as\n",
    "    in the 3DT1 reference image.\n",
    "\n",
    "    Argument:\n",
    "    image -- SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    will be resampled;\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    will be resampled;\n",
    "    ref_image --  SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    will serve as reference image;\n",
    "    \n",
    "    Returns:\n",
    "    resampled_image -- the SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    resulted from resampling;\n",
    "    resampled_label -- the SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    resulted from resampling;\n",
    "    \n",
    "    \"\"\"\n",
    "        \n",
    "    print (\"Running image_and_label_resampler() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    interpolator_image = sitk.sitkBSplineResamplerOrder3\n",
    "    interpolator_label = sitk.sitkNearestNeighbor\n",
    "    \n",
    "    pixelType_image = sitk.sitkFloat32\n",
    "    pixelType_label = sitk.sitkUInt16\n",
    "\n",
    "    transform = sitk.Transform(3, sitk.sitkIdentity)\n",
    "    defaultPixelValue = 0.0\n",
    "  \n",
    "    resampled_image = sitk.Resample(image, ref_image, transform, interpolator_image,\n",
    "                                    defaultPixelValue, pixelType_image, False);               \n",
    "    resampled_label = sitk.Resample(label_image, ref_image, transform, interpolator_label,\n",
    "                                    defaultPixelValue, pixelType_label, False);              \n",
    "    \n",
    "    return (resampled_image, resampled_label)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_and_label(image, label_image, label_value):\n",
    "    \"\"\"\n",
    "    Cropp a grey-level image and a label_image in the shortest box region that\n",
    "    contains the label information in label_image;\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and label_values that will be used to\n",
    "    define the cropping box region and that will be cropped as well;\n",
    "    image -- SimpleItk supported grey-level image (.nift, .nrrd, ...) that\n",
    "    will be cropped;\n",
    "    label_value: integer that represents label information in the label_image; \n",
    "    \n",
    "    Returns:\n",
    "    cropped_image -- the grey-level cropped image \n",
    "    cropped_label -- a binary label image with ones and zeros(background)\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running crop_image_and_label() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    # make label a 1-0 binary label\n",
    "    one_zero_label = sitk.Divide(label_image, int(label_value))\n",
    "    one_zero_label = sitk.Cast(one_zero_label, sitk.sitkFloat32)\n",
    "    only_roi_image = sitk.Multiply(image, one_zero_label)\n",
    "    \n",
    "    shape = sitk.LabelShapeStatisticsImageFilter()\n",
    "    shape.Execute(label_image)\n",
    "    region = shape.GetRegion(int(label_value))\n",
    "    region_index = (region[0], region[1], region[2])\n",
    "    region_size = (region[3], region[4], region[5])\n",
    "    \n",
    "    cropped_image = sitk.RegionOfInterest(only_roi_image, region_size, region_index)\n",
    "    cropped_label = sitk.RegionOfInterest(one_zero_label, region_size, region_index)\n",
    "    cropped_label = sitk.Cast(cropped_label, sitk.sitkUInt16)\n",
    "    \n",
    "    return (cropped_image, cropped_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5aed151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_out_of_bounds(image_size, index):\n",
    "    \"\"\"\n",
    "    Check if a gien pixel index is not inside image region, if it is out of bounds;\n",
    "    \n",
    "    Argument:\n",
    "    image_size -- tuple with x, y, z image sizes;\n",
    "    index -- 2D or 3D tuple that identifies the pixel to be checked; \n",
    "    \n",
    "    Returns:\n",
    "    True -- if index is out of bounds, False, otherwise; \n",
    "    \"\"\"  \n",
    "    \n",
    "    if index[0] >= image_size[0] or index[0] < 0:\n",
    "        return True\n",
    "    elif index[1] >= image_size[1] or index[1] < 0:\n",
    "        return True\n",
    "    elif index[2] >= image_size[2] or index[2] < 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00254753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood_mean(image, label_image, pixel_index):\n",
    "    \"\"\"\n",
    "    Calculates the average grey-level intensity of a given pixel's  neighborhood\n",
    "    (3x3x3 in 3D or 3x3 in 2D);\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and ones;\n",
    "    image -- SimpleItk supported grey-level image (.nift, .nrrd, ...);\n",
    "    pixel_index: 3D or 3D tuple that identifies the pixel will have the\n",
    "    average grey-level intensity calculated for its neighborhood; \n",
    "    \n",
    "    Returns:\n",
    "    neighborhood_mean -- pixel_index neighborhood average intensity \n",
    "    \"\"\"    \n",
    "    size = label_image.GetSize()\n",
    "    \n",
    "    idx = pixel_index\n",
    "    n_sum = 0\n",
    "    counted_pixel = 0\n",
    "    for x in range(idx[0]-1,idx[0]+2):\n",
    "        for y in range(idx[1]-1,idx[1]+2):\n",
    "            for z in range(idx[2]-1,idx[2]+2):\n",
    "                index = (x,y,z)\n",
    "                if not is_out_of_bounds(size, index):\n",
    "                    label_value = label_image.GetPixel(index)\n",
    "                    if label_value == 1:\n",
    "                        n_sum += image.GetPixel(index)\n",
    "                        counted_pixel += 1\n",
    "\n",
    "    neighborhood_mean = int(n_sum/counted_pixel)\n",
    "      \n",
    "    return neighborhood_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40bd805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(image, label_image, label_value):\n",
    "    \"\"\"\n",
    "    Remove outlier pixel intensities by changing outlier values for\n",
    "    the pixels neighborhood average intnsity. A pixel intensity is considered\n",
    "    outlier when it is > mean + 3*std or < mean - 3*std;\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and ones;\n",
    "    image -- SimpleItk supported grey-level image (.nift, .nrrd, ...);\n",
    "    \n",
    "    Returns:\n",
    "    no_outlier_image -- SimpleItk supported grey-level image (.nift, .nrrd, ...)\n",
    "    with o putliers; \n",
    "    \"\"\"\n",
    "    print (\"Running outlier_remova() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    # cleaned final image\n",
    "    no_outlier_image = image\n",
    "    \n",
    "    # Getting grey-level statistics\n",
    "    statistics = sitk.LabelIntensityStatisticsImageFilter()\n",
    "    statistics.Execute(label_image, image)\n",
    "    mean = statistics.GetMean(int(label_value))\n",
    "    std = statistics.GetStandardDeviation(int(label_value))\n",
    "    \n",
    "    size = image.GetSize()    \n",
    "    for x in range(size[0]):\n",
    "        for y in range(size[1]):\n",
    "            for z in range(size[2]):\n",
    "                index = (x,y,z)\n",
    "                label_value = label_image.GetPixel(index)\n",
    "                if label_value == 1:\n",
    "                    image_value = image.GetPixel(index)\n",
    "                    if (image_value > (mean + 3*std)) or (image_value < (mean - 3*std)):\n",
    "                        # print(\"Outlier found: \"+ str(image_value))                        \n",
    "                        neighbourhood_mean = get_neighborhood_mean(image, label_image, index) \n",
    "                        # print(\"New value: \"+ str(neighbourhood_mean))\n",
    "                        no_outlier_image.SetPixel(x, y, z, neighbourhood_mean)               \n",
    "    \n",
    "    return no_outlier_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba4977",
   "metadata": {},
   "source": [
    "## Reading and Preparation Pipeline Call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e47bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_and_label_ready(image_file, label_file, label_value, ref_image_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs the whole image preprocessing pipeline.\n",
    "    \n",
    "    Argument:\n",
    "    image_file -- dir that conttans a SimpleItk supported greylevel image (.nift, .nrrd, ...);\n",
    "    label_file -- dir that conttans a SimpleItk supported binary image (.nift, .nrrd, ...);\n",
    "    label_value -- integer that indicates the pixel value on label_image;\n",
    "    ref_image_file -- dir that conttans a SimpleItk supported greylevel image (.nift, .nrrd, ...) \n",
    "    used as referencen in the histogram matching stage;\n",
    "    \n",
    "    Returns:\n",
    "    final_image -- the post processed SimpleItk supported greylevel image (.nift, .nrrd, ...).\n",
    "    This image contain only the greylevel lesion, outlier-filtered and rescaled;\n",
    "    final_label -- the post processed SimpleItk supported binary image (.nift, .nrrd, ...).\n",
    "    This label does ocuppy the same greylevel image physical space and is cropped containing\n",
    "    only the label lesion region;\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running get_image_and_label_ready() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    image = sitk.ReadImage(image_file, sitk.sitkFloat32)\n",
    "    ref_image = sitk.ReadImage(ref_image_file, sitk.sitkFloat32)\n",
    "    label_image = sitk.ReadImage(label_file, sitk.sitkUInt16)\n",
    "    \n",
    "    # resampling label image into into 1 x 1 x 1 spacing:\n",
    "    resampled_image, resampled_label_image = image_and_label_resampler(image, label_image, ref_image)\n",
    "        \n",
    "    # croppping image and label_image into the interested ROI\n",
    "    cropped_image, final_label = crop_image_and_label(resampled_image, resampled_label_image, label_value)   \n",
    "      \n",
    "    no_outlier_image = outlier_removal(cropped_image, final_label, label_value)\n",
    "\n",
    "    # rouning pixel values to the closest integer in the final image.\n",
    "    final_image = sitk.Round(no_outlier_image)\n",
    "  \n",
    "    return (final_image, final_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b98456e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "'''imageFLAIR_file = \"/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/01016SACH/prep_FLAIR.nrrd\"\n",
    "image3DT1_file = \"/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/01016SACH/prep_3DT1.nrrd\"\n",
    "label_file = \"/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/01016SACH/labels/Consensus-1.nrrd\"\n",
    "label_value = 1\n",
    "ref_image_file = '/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image-Preprocessing-and-Radiomic-Extraction/Histogram-Matching-Reference-Images/MICCAI-01016SACH-3DT1.nrrd'\n",
    "        \n",
    "\n",
    "image = sitk.ReadImage(image3DT1_file, sitk.sitkFloat32)\n",
    "ref_image = sitk.ReadImage(ref_image_file, sitk.sitkFloat32)\n",
    "label_image = sitk.ReadImage(label_file, sitk.sitkUInt16)\n",
    "\n",
    "\n",
    "lb = sitk.GetArrayFromImage(label_image)\n",
    "print(\"antes: \", lb.max(), lb.sum())\n",
    "\n",
    "imageRes, labelRes = image_and_label_resampler(image, label_image, ref_image)\n",
    "\n",
    "print(type(imageRes.GetPixel(0,0,0)))\n",
    "print(type(labelRes.GetPixel(0,0,0)))\n",
    "\n",
    "lb = sitk.GetArrayFromImage(labelRes)\n",
    "print(\"resampled: \", lb.max(), lb.sum())\n",
    "\n",
    "imageCr, labelCr = crop_image_and_label(imageRes, labelRes, label_value)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee19c46",
   "metadata": {},
   "source": [
    "## RADIOMICS Routine: Perform feature extraction for each prepared image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015e6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import radiomics\n",
    "import six\n",
    "import os\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434ce14",
   "metadata": {},
   "source": [
    "### Configuring and extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5f271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_features(image, label, label_value):\n",
    "    \n",
    "    \"\"\"\n",
    "    Configure the setting and run the whole radiomics extraction pipeline.\n",
    "    \n",
    "    Argument:\n",
    "    image -- a SimpleItk supported greylevel image (.nift, .nrrd, ...);\n",
    "    label -- a SimpleItk supported binary image (.nift, .nrrd, ...);\n",
    "    \n",
    "    Returns:\n",
    "    features -- list containing all the features name\n",
    "    values -- list containing all the feature values for the respective label and value\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running extract_features() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    #setting up logger:\n",
    "    # Get the PyRadiomics logger (default log-level = INFO)\n",
    "    logger = radiomics.logger\n",
    "    logger.setLevel(logging.DEBUG)  # set level to DEBUG to include debug log messages in log file\n",
    "\n",
    "    # Set up the handler to write out all log entries to a file\n",
    "    handler = logging.FileHandler(filename='testLog.txt', mode='w')\n",
    "    formatter = logging.Formatter(\"%(levelname)s:%(name)s: %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    # Define settings for signature calculation\n",
    "    settings = {}\n",
    "    settings['binWidth'] = 3\n",
    "    settings['label'] = int(label_value)\n",
    "    \n",
    "    # Initialize feature extractor by settings file (No other configuration must be set)\n",
    "    extractor = radiomics.featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "    # By default, only original is enabled. Optionally enable some image types:\n",
    "    extractor.enableImageTypeByName('Wavelet')\n",
    "    extractor.enableImageTypeByName('LBP3D')\n",
    "    extractor.enableImageTypeByName('Gradient')\n",
    "        \n",
    "    # Disable all classes except firstorder\n",
    "    extractor.disableAllFeatures()\n",
    "\n",
    "    # Enable all features in firstorder\n",
    "    extractor.enableFeatureClassByName('firstorder')\n",
    "    extractor.enableFeatureClassByName('glcm')\n",
    "    extractor.enableFeatureClassByName('glrlm')\n",
    "    extractor.enableFeatureClassByName('glszm')\n",
    "    extractor.enableFeatureClassByName('gldm')\n",
    "    extractor.enableFeatureClassByName('ngtdm')\n",
    "    extractor.enableFeatureClassByName('shape')\n",
    "\n",
    "    # Calculating features\n",
    "    featureVector = extractor.execute(image, label)\n",
    "\n",
    "    # priting and storing features\n",
    "    features = []\n",
    "    values = []\n",
    "\n",
    "    i = 0 # feature counter \n",
    "    for featureName in featureVector.keys():\n",
    "        # the results comes with a 32 lines header. The first condition is to avoid storing those information;\n",
    "        if (i >= 22): \n",
    "            features.append(featureName) \n",
    "            values.append(featureVector[featureName])\n",
    "            print(\"Computed %s: %s\" % (featureName, featureVector[featureName]))\n",
    "        i += 1\n",
    "    \n",
    "    return (features, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b435e7f",
   "metadata": {},
   "source": [
    "### Function to average wavelet and lbp repeated first_order features into single first_order features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7bbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_features(all_features, image_key, ref_features):\n",
    "    \n",
    "    \"\"\"\n",
    "    Average all the feature eextracted from the filter-generated images. In this case,\n",
    "    Wavelet option creates 8 different images and extract first order features from each of such images.\n",
    "    This function average those 8 image features into a single set of first order features.\n",
    "    The same goes for Local Binary pattern filter that generate 3 images and extract first order features \n",
    "    from each of those images.\n",
    "    \n",
    "    Argument:\n",
    "    All_features -- A DataFrame (\"Features\", \"Values\") with all radiomic features extracted\n",
    "    (from original image and from filtered images);\n",
    "    image_key -- type of filter (wavelet, local binary pattern ...);\n",
    "    ref_features -- is a list with the features that will be averaged and kept. E.g. first_order features.\n",
    "    In the original extraction it is extracted all types of features (first order, coocurrence matrix, \n",
    "    run length ...) from the wavelet filtered images. \n",
    "    \n",
    "    Returns:\n",
    "    mean_image_key_features -- DataFrame containing the averaged filtered features;\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running get_averaged_features() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    image_key_features = all_features[all_features['Features'].str.contains(image_key)].copy()\n",
    "    \n",
    "    feat_means = []\n",
    "    for feat in ref_features:\n",
    "        feat_df = image_key_features[image_key_features['Features'].str.endswith('_'+feat)]\n",
    "        mean = feat_df['Values'].mean()\n",
    "        \n",
    "        assert not mean == None, \"Not calculating \" + str(image_key)\n",
    "        \n",
    "        feat_means.append(mean)\n",
    "        \n",
    "    mean_image_key_features = pd.DataFrame({'Features':ref_features, 'Values':feat_means})\n",
    "    mean_image_key_features['Features'] = mean_image_key_features['Features'].map(lambda x: x.replace(x,(image_key + '_' + x)))\n",
    "    \n",
    "    return mean_image_key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bcbce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_sample_feature_extraction(image_file, label_file, label_value, ref_image_file, patient_id, classification):\n",
    "    \n",
    "    \"\"\"\n",
    "    Run the whole feature extraction pipeline for a single patient. Since loading image, \n",
    "    preprocessing, features extraction, features preprocessing, to final feature DataFrame\n",
    "    assempling. Further, it  generates the final feature set, per lesion\n",
    "    sample, with all the features extracted. Average wavelet, local inary pattern,\n",
    "    and gradient image averaged features and combine those features in\n",
    "    to a single feature set DataFrame;\n",
    "    \n",
    "    Argument:\n",
    "    image_file -- Dir of a SimpleItk supported greylevel image (.nift, .nrrd, ...);\n",
    "    label_file -- Dir of a SimpleItk supported binary image (.nift, .nrrd, ...);\n",
    "    label_value -- integer that defines label pixel intensity on label image;\n",
    "    image_type -- A string identifying image type: \"3DT1\" or \"FLAIR\"\n",
    "    patient_id: id of patient and lesion that will identify the extraction;\n",
    "    classification -- A string specifying the sample image classification: \n",
    "    MSL (Multiple Sclerosis Lesions) or CVL (Cerebrovascular Lesions)\n",
    "    \n",
    "    Returns:\n",
    "    final_set - a DataFrame containing original_image extracted features, wavelet, local\n",
    "    binary pattern, and gradient averaged features,the patient_id, and sample lesion classification;\n",
    "    \"\"\"\n",
    "    print (\"Running get_final_set() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    # preparing images for feature extraction:\n",
    "    image, label = get_image_and_label_ready(image_file, label_file, label_value, ref_image_file)\n",
    "    \n",
    "    # calling gross raiomic feature extraction\n",
    "    features, values = extract_features(image, label, label_value)\n",
    "        \n",
    "    # generating a DF with all the extracted features:\n",
    "    all_features = pd.DataFrame({'Features': features, 'Values': values})\n",
    "    \n",
    "    # separating the features calculated over the original image\n",
    "    original = all_features[all_features['Features'].str.contains('original')] \n",
    "    \n",
    "    # store first order feature names to use in the filtered image features averaging:\n",
    "    first_order = original[original['Features'].str.contains('_firstorder_')]\n",
    "    first_order = first_order['Features'].apply(lambda x: x.replace('original_firstorder_',''))\n",
    "    first_order = np.array(first_order)\n",
    "    \n",
    "    # getting averaged first order features calculated over wavelet, local_binary_pattern, and gradient images;\n",
    "    wavelet = get_averaged_features(all_features, 'wavelet', first_order)\n",
    "    lbp = get_averaged_features(all_features, 'lbp', first_order)\n",
    "    gradient = get_averaged_features(all_features, 'gradient', first_order)\n",
    "    \n",
    "    # Gethering all features (original, first_order wavelet and first_order lbp into a single DF)\n",
    "    # Adding Patient_ID at the top row\n",
    "    final_set = pd.DataFrame({'Features':['Patient_ID'], 'Values':patient_id})\n",
    "    final_set = final_set.append(original, ignore_index=True)\n",
    "    final_set = final_set.append(wavelet, ignore_index=True)\n",
    "    final_set = final_set.append(lbp, ignore_index=True)\n",
    "    final_set = final_set.append(gradient, ignore_index=True)\n",
    "    \n",
    "    # appending classification (MS or CVL) into the final set\n",
    "    final_set = final_set.append({'Features':'class', 'Values': classification}, ignore_index=True)\n",
    "    \n",
    "    return (final_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71fdaa",
   "metadata": {},
   "source": [
    "## Feature DataSet Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2b70bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_dataset_feature_extraction(group, image_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read the images and labels files in folders and run feature extraction pipeline for a single patient\n",
    "    lesion label. Since loading image, preprocessing, features extraction, features preprocessing,\n",
    "    to final feature DataFrame for each greoup (MICCAI or WHM) and image_type (3DT1 or FLAIR).\n",
    "    \n",
    "    Argument:\n",
    "    group -- WHM for Cerebrovascular patients, WHM Challenge patients, or MICCAI for Multiple Sclerosis, \n",
    "    MICCAI Challende Patients.\n",
    "    \n",
    "    Returns:\n",
    "    final_dataframe - a DataFrame containing all extracted featuresfor both group accordint to image_type.\n",
    "    There will be four csvs files at the end: WMH_3DT1, WMH_FLAIR, MICCAI_3DT1, MICCAI_FLAIR.\n",
    "    \"\"\"\n",
    "    group = group\n",
    "    image_type = image_type\n",
    "    \n",
    "    # image reference for resampling:\n",
    "    ref_image_file = '/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image-Preprocessing-and-Radiomic-Extraction/Histogram-Matching-Reference-Images/MICCAI-01016SACH-3DT1.nrrd'\n",
    "    \n",
    "    if group == 'MICCAI':\n",
    "        patient_dir = '/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016'\n",
    "        image_3dt1 = 'prep_3DT1.nrrd'\n",
    "        image_flair = 'prep_FLAIR.nrrd'\n",
    "        label_base = 'Consensus'\n",
    "        classification = 'MSL'\n",
    "\n",
    "    if group == 'WMH':\n",
    "        patient_dir = '/home/leonardo/Documents/Projeto-Bizu-MS/WHMChallenge'\n",
    "        image_3dt1 = 'orig/prep_3DT1.nrrd'\n",
    "        image_flair = 'orig/prep_FLAIR.nrrd'\n",
    "        label_base = 'label'\n",
    "        classification = 'CVL'\n",
    "\n",
    "    patient_count = 0\n",
    "    label_count = 0\n",
    "\n",
    "    data_frame = pd.DataFrame() \n",
    "\n",
    "    patients = os.listdir(patient_dir)\n",
    "    for patient in patients:\n",
    "\n",
    "        # Creating patient folder path\n",
    "        patient_folder = os.path.join(patient_dir,patient)\n",
    "\n",
    "        patient_count += 1\n",
    "\n",
    "        if image_type == \"FLAIR\":\n",
    "            image_file = os.path.join(patient_folder, image_flair)\n",
    "        \n",
    "        elif image_type == \"3DT1\":\n",
    "            image_file = os.path.join(patient_folder, image_3dt1)\n",
    "        \n",
    "        if not os.path.isfile(image_file):\n",
    "            print('Images not found!!!!!!!')\n",
    "            print(' ')\n",
    "            print(image_file)\n",
    "            print(' ')\n",
    "            continue\n",
    "\n",
    "        print(image_file)\n",
    "        print(' ')\n",
    "\n",
    "        # setting label_folder:\n",
    "        label_folder = os.path.join(patient_folder,'labels')\n",
    "\n",
    "        if not os.path.isdir(label_folder):\n",
    "            print(\"No Label folder!\")\n",
    "            print(' ')\n",
    "            continue\n",
    "\n",
    "        # listing labels in label_folder\n",
    "        labels = os.listdir(label_folder)    \n",
    "        for label in labels:\n",
    "\n",
    "            # Creating label folder path\n",
    "            label_file = os.path.join(label_folder, label)      \n",
    "\n",
    "            label_value = ''.join(list(filter(lambda x: x.isdigit(), label)))\n",
    "            print(label_value)\n",
    "            print(' ')\n",
    "            \n",
    "            patient_id = group + '_' + patient + '_' + image_type + '_' + label_value\n",
    "            print(patient_id)\n",
    "            print(' ')\n",
    "\n",
    "            patient_lesion_i = run_sample_feature_extraction(image_file, label_file, label_value, \n",
    "                                           ref_image_file, patient_id, classification)\n",
    "\n",
    "            data_frame = data_frame.append(patient_lesion_i['Values'], ignore_index=True)\n",
    "\n",
    "    print(patient_count, label_count)\n",
    "    print(' ')\n",
    "    \n",
    "    data_frame.columns = patient_lesion_i['Features']\n",
    "    \n",
    "    csv_name = group + \"_\"+ image_type + \".csv\"\n",
    "    data_frame.to_csv(csv_name, index=False)\n",
    "    \n",
    "    return (data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eef73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MICCAI_3DT1 = run_dataset_feature_extraction('MICCAI','3DT1')\n",
    "MICCAI_FLAIR = run_dataset_feature_extraction('MICCAI','FLAIR')\n",
    "WMH_3DT1 = run_dataset_feature_extraction('WMH','3DT1')\n",
    "WMH_FLAIR = run_dataset_feature_extraction('WMH','FLAIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572412c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9c4f1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
