{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "705bad2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import SimpleITK as sitk\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "200ee793",
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(sitk.WriteImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed108516",
   "metadata": {},
   "source": [
    "## Image Preprocessing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ee59149",
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_preprocessing(image, ref_image):\n",
    "    \n",
    "    \"\"\"\n",
    "    Apply N4BiasFieldCorrection, Histogram Matching according to a reference image,\n",
    "    Image Z-normalization (mu = 0 and variance = 1), and 8-bit rescaling (0,255) over\n",
    "    the input MRI image.\n",
    "    \n",
    "    Argument:\n",
    "    image -- SimpleItk supported MRI image (.nift, .nrrd, ...), with pixel type sitk.Float32, that\n",
    "    will be corrected;\n",
    "    ref-image -- SimpleItk supported MRI image (.nift, .nrrd, ...), with pixel type sitk.Float32, that\n",
    "    was already N4BiasCorrected;\n",
    "    \n",
    "    Returns:\n",
    "    prep_image -- the MRI image after this preprocessing pipeline;\n",
    "    \"\"\"\n",
    "    print (\"Running image_preprocessing() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    \n",
    "    corrected_image = corrector.Execute(image)\n",
    "\n",
    "    print (\"N4BiasCorrection Done!\")\n",
    "    print (\" \")\n",
    "    \n",
    "    hist_matcher = sitk.HistogramMatchingImageFilter()\n",
    "\n",
    "    matched_image = hist_matcher.Execute(corrected_image, ref_image)\n",
    "    \n",
    "    print (\"Histogram Matching Done!\")\n",
    "    print (\" \")\n",
    "    \n",
    "    z_normalizer = sitk.NormalizeImageFilter()\n",
    "\n",
    "    z_normalized_image = z_normalizer.Execute(matched_image)\n",
    "    \n",
    "    print (\"Image Normalization Done!\")\n",
    "    print (\" \")\n",
    "    \n",
    "    rescaler = sitk.RescaleIntensityImageFilter()\n",
    "    rescaler.SetOutputMinimum(0)\n",
    "    rescaler.SetOutputMaximum(255)    \n",
    "    \n",
    "    rescaled_image = rescaler.Execute(z_normalized_image) \n",
    "    \n",
    "    print (\"Image rescaling Done!\")\n",
    "    print (\" \")\n",
    "    \n",
    "    prep_image = rescaled_image\n",
    "    \n",
    "    return prep_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42b638a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_images(group, image_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read the images and labels files in folders and run feature extraction pipeline for a single patient\n",
    "    lesion label. Since loading image, preprocessing, features extraction, features preprocessing,\n",
    "    to final feature DataFrame for each greoup (MICCAI or WHM) and image_type (3DT1 or FLAIR).\n",
    "    \n",
    "    Argument:\n",
    "    group -- WHM for Cerebrovascular patients, WHM Challenge patients, or MICCAI for Multiple Sclerosis, \n",
    "    MICCAI Challende Patients.\n",
    "    \n",
    "    Returns:\n",
    "    final_dataframe - a DataFrame containing all extracted featuresfor both group accordint to image_type.\n",
    "    There will be four csvs files at the end: WMH_3DT1, WMH_FLAIR, MICCAI_3DT1, MICCAI_FLAIR.\n",
    "    \"\"\"\n",
    "    \n",
    "    if group == 'MICCAI':\n",
    "        patient_dir = '/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016'\n",
    "        image_3dt1 = '3DT1.nii.gz'\n",
    "        image_flair = '3DFLAIR.nii.gz'\n",
    "        prep_image_flair = 'prep_FLAIR.nrrd'\n",
    "        prep_image_3dt1 = 'prep_3DT1.nrrd'\n",
    "\n",
    "    if group == 'WMH':\n",
    "        patient_dir = '/home/leonardo/Documents/Projeto-Bizu-MS/WHMChallenge'\n",
    "        image_3dt1 = 'orig/3DT1.nii.gz'\n",
    "        image_flair = 'orig/FLAIR.nii.gz'\n",
    "        prep_image_flair = 'orig/prep_FLAIR.nrrd'\n",
    "        prep_image_3dt1 = 'orig/prep_3DT1.nrrd'\n",
    "     \n",
    "    patient_count = 0\n",
    "\n",
    "    patients = os.listdir(patient_dir)\n",
    "    for patient in patients:\n",
    "        \n",
    "        print(\"Patient \" + str(patient_count))\n",
    "        print(' ')\n",
    "        \n",
    "        # Creating patient folder path\n",
    "        patient_folder = os.path.join(patient_dir,patient)\n",
    "        print(patient_folder)\n",
    "        print(' ')\n",
    "\n",
    "        if image_type == \"FLAIR\":\n",
    "            image_file = os.path.join(patient_folder, image_flair)\n",
    "            prep_image_name = os.path.join(patient_folder, prep_image_flair)\n",
    "            ref_image_file = '/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image-Preprocessing-and-Radiomic-Extraction/HistogramMatchingReferenceImages/MICCAI-01016SACH-3FLAIR.nrrd'\n",
    "        \n",
    "        elif image_type == \"3DT1\":\n",
    "            image_file = os.path.join(patient_folder, image_3dt1)\n",
    "            prep_image_name = os.path.join(patient_folder, prep_image_3dt1)\n",
    "            ref_image_file = '/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image-Preprocessing-and-Radiomic-Extraction/HistogramMatchingReferenceImages/MICCAI-01016SACH-3DT1.nrrd'\n",
    "        \n",
    "        if not os.path.isfile(image_file):\n",
    "            print('OOOOOOOOOOOOOO - Images not found! - XXXXXXXXXXXX')\n",
    "            print(' ')\n",
    "            print(image_file)\n",
    "            print(' ')\n",
    "            \n",
    "            continue\n",
    "        \n",
    "        print(image_file)\n",
    "        print(' ')\n",
    "        print(ref_image_file)\n",
    "        print(' ')\n",
    "        print(prep_image_name)\n",
    "        print(' ')\n",
    "        \n",
    "        image = sitk.ReadImage(image_file, sitk.sitkFloat32)\n",
    "        ref_image = sitk.ReadImage(ref_image_file, sitk.sitkFloat32)\n",
    "\n",
    "        prep_image = image_preprocessing(image, ref_image)\n",
    "        \n",
    "        sitk.WriteImage(prep_image, prep_image_name)\n",
    "        \n",
    "        patient_count += 1\n",
    "        \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d275c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_file = \"/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/01016SACH/3DFLAIR.nii.gz\"\n",
    "\n",
    "image = sitk.ReadImage(image_file, sitk.sitkFloat32)\n",
    "\n",
    "corrector = sitk.N4BiasFieldCorrectionImageFilter()\n",
    "    \n",
    "corrected_image = corrector.Execute(image)\n",
    "\n",
    "sitk.WriteImage(corrected_image, '3DFlair.nrrd')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb8753d",
   "metadata": {},
   "source": [
    "### Calling make images for both groups, both image types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f8149c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_images('WMH','3DT1')\n",
    "make_images('WMH','FLAIR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9a621b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient 0\n",
      " \n",
      "/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/08027SYBR\n",
      " \n",
      "/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/08027SYBR/3DT1.nii.gz\n",
      " \n",
      "/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image-Preprocessing-and-Radiomic-Extraction/HistogramMatchingReferenceImages/MICCAI-01016SACH-3DT1.nrrd\n",
      " \n",
      "/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016/08027SYBR/prep_3DT1.nrrd\n",
      " \n",
      "Running image_preprocessing() routine.\n",
      " \n"
     ]
    }
   ],
   "source": [
    "make_images('MICCAI','3DT1')\n",
    "make_images('MICCAI','FLAIR')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3188a1d0",
   "metadata": {},
   "source": [
    "## Image preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3290076",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_resampler(image, reference_image):\n",
    "    \"\"\"\n",
    "    Resample image into the reference_image physical space (origing, spacing, direction).\n",
    "    At the end image will have same voxrl size as reference_image.\n",
    "    \n",
    "    Argument:\n",
    "    image -- SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    will be resampled;\n",
    "    reference_image -- SimpleItk supported binary image (.nift, .nrrd, ...) that\n",
    "    will be used as reference for origin, spacing, and direction; \n",
    "    \n",
    "    Returns:\n",
    "    resampled_image -- image with same physical space information as reference_image;\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running label_resampler() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    interpolator = sitk.sitkNearestNeighbor\n",
    "    transform = sitk.Transform(3, sitk.sitkIdentity)\n",
    "    resampled_image = sitk.Resample(image, reference_image, transform,\n",
    "                              interpolator, 0.0, sitk.sitkUInt16)    \n",
    "    \n",
    "    return resampled_image    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a05267a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_label(label_image, label_value):\n",
    "    \"\"\"\n",
    "    Receives a binary image with zeros (background) and label_value intensities and\n",
    "    change it into a binary image with zeros and ones where there was\n",
    "    label_value intensities;\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and label_values;\n",
    "    label_value: integer that represents label information in the label_image; \n",
    "    \n",
    "    Returns:\n",
    "    one_zero_label -- a binary label image with ones and zeros(background)\n",
    "    \"\"\"\n",
    "    print (\"Running prepare_label() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    one_zero_label_raw = sitk.Divide(label_image, int(label_value))\n",
    "    one_zero_label = sitk.Cast(one_zero_label_raw, sitk.sitkUInt16)\n",
    "    \n",
    "    return one_zero_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4d3e321f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_image_and_label(image, label_image, label_value):\n",
    "    \"\"\"\n",
    "    Cropp a grey-level image and a label_image in the shortest box region that\n",
    "    contains the label information in label_image;\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and label_values that will be used to\n",
    "    define the cropping box region and that will be cropped as well;\n",
    "    image -- SimpleItk supported grey-level image (.nift, .nrrd, ...) that\n",
    "    will be cropped;\n",
    "    label_value: integer that represents label information in the label_image; \n",
    "    \n",
    "    Returns:\n",
    "    cropped_image -- the grey-level cropped image \n",
    "    cropped_label -- a binary label image with ones and zeros(background)\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running crop_image_and_label() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    one_zero_label = prepare_label(label_image, label_value)\n",
    "    image_casted = sitk.Cast(image, sitk.sitkUInt16)\n",
    "    only_roi_image = sitk.Multiply(one_zero_label,image_casted)\n",
    "    \n",
    "    shape = sitk.LabelShapeStatisticsImageFilter()\n",
    "    shape.Execute(one_zero_label)\n",
    "    region = shape.GetRegion(1)\n",
    "    region_index = (region[0], region[1], region[2])\n",
    "    region_size = (region[3], region[4], region[5])\n",
    "    \n",
    "    cropped_image = sitk.RegionOfInterest(only_roi_image, region_size, region_index)\n",
    "    cropped_label = sitk.RegionOfInterest(one_zero_label, region_size, region_index)\n",
    "    \n",
    "    return (cropped_image, cropped_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5aed151",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_out_of_bounds(image_size, index):\n",
    "    \"\"\"\n",
    "    Check if a gien pixel index is not inside image region, if it is out of bounds;\n",
    "    \n",
    "    Argument:\n",
    "    image_size -- tuple with x, y, z image sizes;\n",
    "    index -- 2D or 3D tuple that identifies the pixel to be checked; \n",
    "    \n",
    "    Returns:\n",
    "    True -- if index is out of bounds, False, otherwise; \n",
    "    \"\"\"  \n",
    "    \n",
    "    if index[0] >= image_size[0] or index[0] < 0:\n",
    "        return True\n",
    "    elif index[1] >= image_size[1] or index[1] < 0:\n",
    "        return True\n",
    "    elif index[2] >= image_size[2] or index[2] < 0:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00254753",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_neighborhood_mean(image, label_image, pixel_index):\n",
    "    \"\"\"\n",
    "    Calculates the average grey-level intensity of a given pixel's  neighborhood\n",
    "    (3x3x3 in 3D or 3x3 in 2D);\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and ones;\n",
    "    image -- SimpleItk supported grey-level image (.nift, .nrrd, ...);\n",
    "    pixel_index: 3D or 3D tuple that identifies the pixel will have the\n",
    "    average grey-level intensity calculated for its neighborhood; \n",
    "    \n",
    "    Returns:\n",
    "    neighborhood_mean -- pixel_index neighborhood average intensity \n",
    "    \"\"\"    \n",
    "    size = label_image.GetSize()\n",
    "    \n",
    "    idx = pixel_index\n",
    "    n_sum = 0\n",
    "    counted_pixel = 0\n",
    "    for x in range(idx[0]-1,idx[0]+2):\n",
    "        for y in range(idx[1]-1,idx[1]+2):\n",
    "            for z in range(idx[2]-1,idx[2]+2):\n",
    "                index = (x,y,z)\n",
    "                if not is_out_of_bounds(size, index):\n",
    "                    label_value = label_image.GetPixel(index)\n",
    "                    if label_value == 1:\n",
    "                        n_sum += image.GetPixel(index)\n",
    "                        counted_pixel += 1\n",
    "\n",
    "    neighborhood_mean = int(n_sum/counted_pixel)\n",
    "      \n",
    "    return neighborhood_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "40bd805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outlier_removal(image, label_image):\n",
    "    \"\"\"\n",
    "    Remove outlier pixel intensities by changing outlier values for\n",
    "    the pixels neighborhood average intnsity. A pixel intensity is considered\n",
    "    outlier when it is > mean + 3*std or < mean - 3*std;\n",
    "    \n",
    "    Argument:\n",
    "    label_image -- SimpleItk supported binary image (.nift, .nrrd, ...) with\n",
    "    intensities: zeros (background) and ones;\n",
    "    image -- SimpleItk supported grey-level image (.nift, .nrrd, ...);\n",
    "    \n",
    "    Returns:\n",
    "    no_outlier_image -- SimpleItk supported grey-level image (.nift, .nrrd, ...)\n",
    "    with o putliers; \n",
    "    \"\"\"\n",
    "    print (\"Running outlier_remova() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    # cleaned final image\n",
    "    no_outlier_image = image\n",
    "    \n",
    "    # Getting grey-level statistics\n",
    "    statistics = sitk.LabelIntensityStatisticsImageFilter()\n",
    "    statistics.Execute(label_image, image)\n",
    "    mean = statistics.GetMean(1)\n",
    "    std = statistics.GetStandardDeviation(1)\n",
    "    \n",
    "    size = image.GetSize()    \n",
    "    for x in range(size[0]):\n",
    "        for y in range(size[1]):\n",
    "            for z in range(size[2]):\n",
    "                index = (x,y,z)\n",
    "                label_value = label_image.GetPixel(index)\n",
    "                if label_value == 1:\n",
    "                    image_value = image.GetPixel(index)\n",
    "                    if (image_value > (mean + 3*std)) or (image_value < (mean - 3*std)):\n",
    "                        # print(\"Outlier found: \"+ str(image_value))                        \n",
    "                        neighbourhood_mean = get_neighborhood_mean(image, label_image, index) \n",
    "                        # print(\"New value: \"+ str(neighbourhood_mean))\n",
    "                        no_outlier_image.SetPixel(x, y, z, neighbourhood_mean)               \n",
    "    \n",
    "    return no_outlier_image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abba4977",
   "metadata": {},
   "source": [
    "## Reading and Preparation Pipeline Call "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2e47bc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image_and_label_ready(image_file, label_file, label_value, ref_image_file):\n",
    "    \n",
    "    \"\"\"\n",
    "    Runs the whole image preprocessing pipeline.\n",
    "    \n",
    "    Argument:\n",
    "    image_file -- dir that conttans a SimpleItk supported greylevel image (.nift, .nrrd, ...);\n",
    "    label_file -- dir that conttans a SimpleItk supported binary image (.nift, .nrrd, ...);\n",
    "    label_value -- integer that indicates the pixel value on label_image;\n",
    "    ref_image_file -- dir that conttans a SimpleItk supported greylevel image (.nift, .nrrd, ...) \n",
    "    used as referencen in the histogram matching stage;\n",
    "    \n",
    "    Returns:\n",
    "    final_image -- the post processed SimpleItk supported greylevel image (.nift, .nrrd, ...).\n",
    "    This image contain only the greylevel lesion, outlier-filtered and rescaled;\n",
    "    final_label -- the post processed SimpleItk supported binary image (.nift, .nrrd, ...).\n",
    "    This label does ocuppy the same greylevel image physical space and is cropped containing\n",
    "    only the label lesion region;\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running get_image_and_label_ready() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    label_image = sitk.ReadImage(label_file, sitk.sitkInt8)\n",
    "    image = sitk.ReadImage(image_file, sitk.sitkFloat32)\n",
    "    ref_image = sitk.ReadImage(ref_image_file, sitk.sitkFloat32)\n",
    "    \n",
    "    # resampling label image into 3DT1 space:\n",
    "    resampled_label_image = label_resampler(label_image, image)\n",
    "    \n",
    "    prep_image = image_preprocessing(image, ref_image)\n",
    "    \n",
    "    cropped_image, cropped_label = crop_image_and_label(prep_image, resampled_label_image, label_value)\n",
    "    \n",
    "    no_outlier_image = outlier_removal(cropped_image, cropped_label)\n",
    "\n",
    "    final_image, final_label = no_outlier_image, cropped_label\n",
    "  \n",
    "    return (final_image, final_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ee19c46",
   "metadata": {},
   "source": [
    "## RADIOMICS Routine: Perform feature extraction for each prepared image and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "015e6bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import radiomics\n",
    "import six\n",
    "import os\n",
    "import sys\n",
    "import logging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6434ce14",
   "metadata": {},
   "source": [
    "### Configuring and extracting features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99c5f271",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def extract_features(image, label):\n",
    "    \n",
    "    \"\"\"\n",
    "    Configure the setting and run the whole radiomics extraction pipeline.\n",
    "    \n",
    "    Argument:\n",
    "    image -- a SimpleItk supported greylevel image (.nift, .nrrd, ...);\n",
    "    label -- a SimpleItk supported binary image (.nift, .nrrd, ...);\n",
    "    \n",
    "    Returns:\n",
    "    features -- list containing all the features name\n",
    "    values -- list containing all the feature values for the respective label and value\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running extract_features() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    #setting up logger:\n",
    "    # Get the PyRadiomics logger (default log-level = INFO)\n",
    "    logger = radiomics.logger\n",
    "    logger.setLevel(logging.DEBUG)  # set level to DEBUG to include debug log messages in log file\n",
    "\n",
    "    # Set up the handler to write out all log entries to a file\n",
    "    handler = logging.FileHandler(filename='testLog.txt', mode='w')\n",
    "    formatter = logging.Formatter(\"%(levelname)s:%(name)s: %(message)s\")\n",
    "    handler.setFormatter(formatter)\n",
    "    logger.addHandler(handler)\n",
    "\n",
    "    # Define settings for signature calculation\n",
    "    settings = {}\n",
    "    settings['binWidth'] = 3\n",
    "    settings['label'] = 1\n",
    "    \n",
    "    # Initialize feature extractor by settings file (No other configuration must be set)\n",
    "    extractor = radiomics.featureextractor.RadiomicsFeatureExtractor(**settings)\n",
    "\n",
    "    # By default, only original is enabled. Optionally enable some image types:\n",
    "    extractor.enableImageTypeByName('Wavelet')\n",
    "    extractor.enableImageTypeByName('LBP3D')\n",
    "    extractor.enableImageTypeByName('Gradient')\n",
    "        \n",
    "    # Disable all classes except firstorder\n",
    "    extractor.disableAllFeatures()\n",
    "\n",
    "    # Enable all features in firstorder\n",
    "    extractor.enableFeatureClassByName('firstorder')\n",
    "    extractor.enableFeatureClassByName('glcm')\n",
    "    extractor.enableFeatureClassByName('glrlm')\n",
    "    extractor.enableFeatureClassByName('glszm')\n",
    "    extractor.enableFeatureClassByName('gldm')\n",
    "    extractor.enableFeatureClassByName('ngtdm')\n",
    "    extractor.enableFeatureClassByName('shape')\n",
    "\n",
    "    # Calculating features\n",
    "    featureVector = extractor.execute(image, label)\n",
    "\n",
    "    # priting and storing features\n",
    "    features = []\n",
    "    values = []\n",
    "\n",
    "    i = 0 # feature counter \n",
    "    for featureName in featureVector.keys():\n",
    "        # the results comes with a 32 lines header. The first condition is to avoid storing those information;\n",
    "        if (i >= 22): \n",
    "            features.append(featureName) \n",
    "            values.append(featureVector[featureName])\n",
    "            print(\"Computed %s: %s\" % (featureName, featureVector[featureName]))\n",
    "        i += 1\n",
    "    \n",
    "    return (features, values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b435e7f",
   "metadata": {},
   "source": [
    "### Function to average wavelet and lbp repeated first_order features into single first_order features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a7bbb35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_averaged_features(all_features, image_key, ref_features):\n",
    "    \n",
    "    \"\"\"\n",
    "    Average all the feature eextracted from the filter-generated images. In this case,\n",
    "    Wavelet option creates 8 different images and extract first order features from each of such images.\n",
    "    This function average those 8 image features into a single set of first order features.\n",
    "    The same goes for Local Binary pattern filter that generate 3 images and extract first order features \n",
    "    from each of those images.\n",
    "    \n",
    "    Argument:\n",
    "    All_features -- A DataFrame (\"Features\", \"Values\") with all radiomic features extracted\n",
    "    (from original image and from filtered images);\n",
    "    image_key -- type of filter (wavelet, local binary pattern ...);\n",
    "    ref_features -- is a list with the features that will be averaged and kept. E.g. first_order features.\n",
    "    In the original extraction it is extracted all types of features (first order, coocurrence matrix, \n",
    "    run length ...) from the wavelet filtered images. \n",
    "    \n",
    "    Returns:\n",
    "    mean_image_key_features -- DataFrame containing the averaged filtered features;\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running get_averaged_features() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    image_key_features = all_features[all_features['Features'].str.contains(image_key)].copy()\n",
    "    \n",
    "    feat_means = []\n",
    "    for feat in ref_features:\n",
    "        feat_df = image_key_features[image_key_features['Features'].str.endswith('_'+feat)]\n",
    "        mean = feat_df['Values'].mean()\n",
    "        \n",
    "        assert not mean == None, \"Not calculating \" + str(image_key)\n",
    "        \n",
    "        feat_means.append(mean)\n",
    "        \n",
    "    mean_image_key_features = pd.DataFrame({'Features':ref_features, 'Values':feat_means})\n",
    "    mean_image_key_features['Features'] = mean_image_key_features['Features'].map(lambda x: x.replace(x,(image_key + '_' + x)))\n",
    "    \n",
    "    return mean_image_key_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1324b207",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_final_feature_set(features, values, patient_id):\n",
    "    \n",
    "    \"\"\"\n",
    "    Generates the final from all the features extracted.\n",
    "    separate original_image features, call wavelet and local inary pattern averaged features and\n",
    "    combine those features in to a single DataFrame;\n",
    "    \n",
    "    Argument:\n",
    "    features -- list with names of all radiomic features extracted;\n",
    "    values -- list with all radiomic feature values extracted;\n",
    "    patient_id: id of patient and lesion that will identify the extraction;\n",
    "    \n",
    "    Returns:\n",
    "    final_set - a DataFrame containing original_image extracted features, wavelet and local\n",
    "    binary pattern extracted features, and the patient_id;\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running generate_final_feature_set() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    # generating a DF with all the extracted features:\n",
    "    all_features = pd.DataFrame({'Features': features, 'Values': values})\n",
    "    \n",
    "    # separating the features calculated over the original image\n",
    "    original = all_features[all_features['Features'].str.contains('original')] \n",
    "    \n",
    "    # store first order feature names to use in the filtered image features averaging:\n",
    "    first_order = original[original['Features'].str.contains('_firstorder_')]\n",
    "    first_order = first_order['Features'].apply(lambda x: x.replace('original_firstorder_',''))\n",
    "    first_order = np.array(first_order)\n",
    "    first_order\n",
    "    \n",
    "    # getting averaged first order features calculated over wavelet and local_binary_pattern images;\n",
    "    wavelet = get_averaged_features(all_features, 'wavelet', first_order)\n",
    "    lbp = get_averaged_features(all_features, 'lbp', first_order)\n",
    "    gradient = get_averaged_features(all_features, 'gradient', first_order)\n",
    "    \n",
    "    # Gethering all features (original, first_order wavelet and first_order lbp into a single DF)\n",
    "    # Adding Patient_ID at the top row\n",
    "    final_set = pd.DataFrame({'Features':['Patient_ID'], 'Values':patient_id})\n",
    "    final_set = final_set.append(original, ignore_index=True)\n",
    "    final_set = final_set.append(wavelet, ignore_index=True)\n",
    "    final_set = final_set.append(lbp, ignore_index=True)\n",
    "    final_set = final_set.append(gradient, ignore_index=True)\n",
    "    final_set\n",
    "    \n",
    "    return(final_set)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1bcbce7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_set(image_file, label_file, label_value, ref_image_file, patient_id, classification):\n",
    "    \n",
    "    \"\"\"\n",
    "    Run the whole feature extraction pipeline for a single patient. Since loading image, \n",
    "    preprocessing, features extraction, features preprocessing, to final feature DataFrame\n",
    "    assempling.\n",
    "    \n",
    "    Argument:\n",
    "    image_file -- Dir of a SimpleItk supported greylevel image (.nift, .nrrd, ...);\n",
    "    label_file -- Dir of a SimpleItk supported binary image (.nift, .nrrd, ...);\n",
    "    label_value -- integer that defines label pixel intensity on label image;\n",
    "    resample -- tells if the label image needs resampling into grey-level image physical space;\n",
    "    \n",
    "    Returns:\n",
    "    final_set - a DataFrame containing original_image extracted features, wavelet and local\n",
    "    binary pattern extracted features, and the patient_id;\n",
    "    \"\"\"\n",
    "    \n",
    "    print (\"Running get_final_set() routine.\")\n",
    "    print (\" \")\n",
    "    \n",
    "    # getting preprocessed images:\n",
    "    image, label = get_image_and_label_ready(image_file, label_file, label_value, ref_image_file)\n",
    "    \n",
    "    features, values = extract_features(image, label)\n",
    "    final_set = generate_final_feature_set(features, values, patient_id)\n",
    "    \n",
    "    # appending number of pixels into the final set\n",
    "    final_set = final_set.append({'Features':'class', 'Values': classification}, ignore_index=True)\n",
    "    \n",
    "    return (final_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe71fdaa",
   "metadata": {},
   "source": [
    "## Feature DataSet Generation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2b70bf2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run(group, image_type):\n",
    "    \n",
    "    \"\"\"\n",
    "    Read the images and labels files in folders and run feature extraction pipeline for a single patient\n",
    "    lesion label. Since loading image, preprocessing, features extraction, features preprocessing,\n",
    "    to final feature DataFrame for each greoup (MICCAI or WHM) and image_type (3DT1 or FLAIR).\n",
    "    \n",
    "    Argument:\n",
    "    group -- WHM for Cerebrovascular patients, WHM Challenge patients, or MICCAI for Multiple Sclerosis, \n",
    "    MICCAI Challende Patients.\n",
    "    \n",
    "    Returns:\n",
    "    final_dataframe - a DataFrame containing all extracted featuresfor both group accordint to image_type.\n",
    "    There will be four csvs files at the end: WMH_3DT1, WMH_FLAIR, MICCAI_3DT1, MICCAI_FLAIR.\n",
    "    \"\"\"\n",
    "        \n",
    "    group = group\n",
    "    image_type = image_type\n",
    "    \n",
    "    if group == 'MICCAI':\n",
    "        patient_dir = '/home/leonardo/Documents/Projeto-Bizu-MS/MICCAI2016'\n",
    "        image_3dt1 = '3DT1.nii.gz'\n",
    "        image_flair = '3DFLAIR.nii.gz'\n",
    "        label_base = 'Consensus'\n",
    "        classification = 0\n",
    "\n",
    "    if group == 'WMH':\n",
    "        patient_dir = '/home/leonardo/Documents/Projeto-Bizu-MS/WHMChallenge'\n",
    "        image_3dt1 = 'orig/3DT1.nii.gz'\n",
    "        image_flair = 'orig/FLAIR.nii.gz'\n",
    "        label_base = 'label'\n",
    "        classification = 1\n",
    "\n",
    "    patient_count = 0\n",
    "    label_count = 0\n",
    "\n",
    "    data_frame = pd.DataFrame() \n",
    "\n",
    "    patients = os.listdir(patient_dir)\n",
    "    for patient in patients:\n",
    "\n",
    "        # Creating patient folder path\n",
    "        patient_folder = os.path.join(patient_dir,patient)\n",
    "\n",
    "        patient_count += 1\n",
    "\n",
    "        if image_type == \"FLAIR\":\n",
    "            image_file = os.path.join(patient_folder, image_flair)\n",
    "            ref_image_file = '/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image Preprocessing and Radiomic Extraction/HistogramMatchingReferenceImages/MICCAI-01016SACH-3FLAIR.nrrd'\n",
    "        elif image_type == \"3DT1\":\n",
    "            image_file = os.path.join(patient_folder, image_3dt1)\n",
    "            ref_image_file = '/home/leonardo/Documents/Projeto-Bizu-MS/Classification-of-MRI-Hiperintense-Brain-Lesions/Image Preprocessing and Radiomic Extraction/HistogramMatchingReferenceImages/MICCAI-01016SACH-3DT1.nrrd'\n",
    "        \n",
    "        if not os.path.isfile(image_file):\n",
    "            print('Images not found!!!!!!!')\n",
    "            print(image_file)\n",
    "            print(' ')\n",
    "            continue\n",
    "\n",
    "        print(image_file)\n",
    "        print(' ')\n",
    "\n",
    "        # setting label_folder:\n",
    "        label_folder = os.path.join(patient_folder,'labels')\n",
    "\n",
    "        if not os.path.isdir(label_folder):\n",
    "            print(\"No Label folder!\")\n",
    "            print(' ')\n",
    "            continue\n",
    "\n",
    "        # listing labels in label_folder\n",
    "        labels = os.listdir(label_folder)    \n",
    "        for label in labels:\n",
    "\n",
    "            # Creating label folder path\n",
    "            label_file = os.path.join(label_folder, label)      \n",
    "\n",
    "            label_value = ''.join(list(filter(lambda x: x.isdigit(), label)))\n",
    "\n",
    "            patient_id = group + '_' + patient + '_' + image_type + '_' + label_value\n",
    "            print(patient_id)\n",
    "            print(' ')\n",
    "\n",
    "            patient_lesion_i = get_final_set(image_file, label_file, label_value, \n",
    "                                           ref_image_file, patient_id, classification)\n",
    "\n",
    "            data_frame = data_frame.append(patient_lesion_i['Values'], ignore_index=True)\n",
    "\n",
    "    print(patient_count, label_count)\n",
    "    print(' ')\n",
    "    data_frame.columns = patient_lesion_i['Features']\n",
    "    \n",
    "    csv_name = group + \"_\"+ image_type + \".csv\"\n",
    "    data_frame.to_csv(csv_name)\n",
    "    \n",
    "    return (data_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eef73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "WMH_3DT1.to_csv(index=False)\n",
    "WMH_FLAIR.to_csv(index=False)\n",
    "MICCAI_3DT1.to_csv(index=False)\n",
    "MICCAI_FLAIR.to_csv(index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572412c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
